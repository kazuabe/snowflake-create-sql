# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import streamlit as st
from snowflake.snowpark.context import get_active_session
import pandas as pd
import uuid
import re
import logging
from typing import Optional, List, Dict, Any

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Streamlitã‚¢ãƒ—ãƒªã®åŸºæœ¬è¨­å®š ---
st.set_page_config(layout="wide")
st.title('åˆå¿ƒè€…å‘ã‘SQLã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼')

# --- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š ---
def sanitize_identifier(identifier: Optional[str]) -> Optional[str]:
    """è­˜åˆ¥å­ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã™ã‚‹"""
    if not identifier or not isinstance(identifier, str):
        return None
    # è¨±å¯ã•ã‚Œã‚‹æ–‡å­—ã®ã¿ã‚’æ®‹ã™
    sanitized = re.sub(r'[^a-zA-Z0-9_"]', '', identifier)
    return sanitized if sanitized else None

def validate_sql_value(value: Optional[str]) -> bool:
    """SQLå€¤ã®æ¤œè¨¼"""
    if not value or not isinstance(value, str):
        return True
    # å±é™ºãªæ–‡å­—åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
    dangerous_patterns = [
        r'--',  # SQLã‚³ãƒ¡ãƒ³ãƒˆ
        r'/\*.*\*/',  # SQLã‚³ãƒ¡ãƒ³ãƒˆ
        r';\s*$',  # ã‚»ãƒŸã‚³ãƒ­ãƒ³
        r'DROP\s+',  # DROPæ–‡
        r'DELETE\s+',  # DELETEæ–‡
        r'UPDATE\s+',  # UPDATEæ–‡
        r'INSERT\s+',  # INSERTæ–‡
        r'CREATE\s+',  # CREATEæ–‡
        r'ALTER\s+',  # ALTERæ–‡
    ]
    for pattern in dangerous_patterns:
        if re.search(pattern, value, re.IGNORECASE):
            return False
    return True

# --- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°é–¢æ•° ---
def handle_database_error(operation: str, error: Exception) -> None:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®çµ±ä¸€å‡¦ç†"""
    error_msg = f"{operation}ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(error)}"
    logger.error(error_msg)
    st.error(error_msg)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if "connection" in str(error).lower():
        st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    elif "permission" in str(error).lower():
        st.info("å¿…è¦ãªæ¨©é™ãŒã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    elif "not found" in str(error).lower():
        st.info("æŒ‡å®šã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– ---
if 'select_items' not in st.session_state:
    st.session_state.select_items = []
if 'where_conditions' not in st.session_state:
    st.session_state.where_conditions = []
if 'joins' not in st.session_state:
    st.session_state.joins = []

# --- Snowflakeã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å–å¾— ---
try:
    session = get_active_session()
    logger.info("Snowflakeã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ­£å¸¸ã«å–å¾—ã—ã¾ã—ãŸ")
except Exception as e:
    error_msg = f"Snowflakeã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
    logger.error(error_msg)
    st.error(error_msg)
    st.info("ã“ã®ã‚¢ãƒ—ãƒªã¯ 'Streamlit in Snowflake' ç’°å¢ƒã§ã®å®Ÿè¡Œã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚")
    st.stop()

# --- ç”¨èªå®šç¾© ---
JOIN_TYPES = {
    'INNER JOIN': 'å†…éƒ¨çµåˆ',
    'LEFT JOIN': 'å·¦å¤–éƒ¨çµåˆ'
}
AGG_FUNCS = {
    'none': '(ãªã—)',
    'COUNT': 'ä»¶æ•°',
    'SUM': 'åˆè¨ˆ',
    'AVG': 'å¹³å‡',
    'MIN': 'æœ€å°',
    'MAX': 'æœ€å¤§',
    'COUNT(DISTINCT)': 'ä»¶æ•°ï¼ˆé‡è¤‡ãªã—ï¼‰'
}
OPERATORS = {
    '=': 'ç­‰ã—ã„',
    '!=': 'ç­‰ã—ããªã„',
    '>': 'ã‚ˆã‚Šå¤§ãã„',
    '>=': 'ä»¥ä¸Š',
    '<': 'ã‚ˆã‚Šå°ã•ã„',
    '<=': 'ä»¥ä¸‹',
    'LIKE_PARTIAL': 'éƒ¨åˆ†ä¸€è‡´',
    'LIKE_FORWARD': 'å‰æ–¹ä¸€è‡´',
    'LIKE_BACKWARD': 'å¾Œæ–¹ä¸€è‡´',
    'IN': 'è¤‡æ•°é¸æŠ',
    'IS NULL': 'ç©ºã®å€¤',
    'IS NOT NULL': 'ç©ºã§ãªã„å€¤'
}

# --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢æ•° ---
@st.cache_data(show_spinner=False)
def get_table_definition(db: Optional[str], schema: Optional[str], table: Optional[str]) -> pd.DataFrame:
    """æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®å®šç¾©ï¼ˆã‚«ãƒ©ãƒ åã¨ãƒ‡ãƒ¼ã‚¿å‹ï¼‰ã‚’DataFrameã§å–å¾—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    if not all([db, schema, table]):
        return pd.DataFrame()
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
    db = sanitize_identifier(db)
    schema = sanitize_identifier(schema)
    table = sanitize_identifier(table)
    
    if not all([db, schema, table]):
        logger.warning("ç„¡åŠ¹ãªè­˜åˆ¥å­ãŒæŒ‡å®šã•ã‚Œã¾ã—ãŸ")
        return pd.DataFrame()
    
    try:
        query = f"""
            SELECT COLUMN_NAME, DATA_TYPE
            FROM "{db}".INFORMATION_SCHEMA.COLUMNS
            WHERE TABLE_SCHEMA = '{schema}'
            AND TABLE_NAME = '{table}'
            ORDER BY ORDINAL_POSITION;
        """
        result = session.sql(query).to_pandas()
        logger.info(f"ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã‚’æ­£å¸¸ã«å–å¾—ã—ã¾ã—ãŸ: {db}.{schema}.{table}")
        return result
    except Exception as e:
        handle_database_error("ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã®å–å¾—", e)
        return pd.DataFrame()

@st.cache_data(show_spinner=False)
def get_qualified_table_columns(db: Optional[str], schema: Optional[str], table: Optional[str]) -> List[str]:
    """ãƒ†ãƒ¼ãƒ–ãƒ«åã§ä¿®é£¾ã•ã‚ŒãŸã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    if not all([db, schema, table]):
        return []
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
    db = sanitize_identifier(db)
    schema = sanitize_identifier(schema)
    table = sanitize_identifier(table)
    
    if not all([db, schema, table]):
        logger.warning("ç„¡åŠ¹ãªè­˜åˆ¥å­ãŒæŒ‡å®šã•ã‚Œã¾ã—ãŸ")
        return []
    
    try:
        query = f'DESC TABLE "{db}"."{schema}"."{table}"'
        cols_df = session.sql(query).collect()
        result = [f'"{table}"."{c["name"]}"' for c in cols_df]
        logger.info(f"ã‚«ãƒ©ãƒ æƒ…å ±ã‚’æ­£å¸¸ã«å–å¾—ã—ã¾ã—ãŸ: {db}.{schema}.{table} ({len(result)} columns)")
        return result
    except Exception as e:
        handle_database_error("ã‚«ãƒ©ãƒ æƒ…å ±ã®å–å¾—", e)
        return []

# --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•° ---
def add_item(session_state_key: str, parent_id: Optional[str] = None) -> None:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¿½åŠ ã™ã‚‹"""
    item_id = str(uuid.uuid4())
    new_item: Dict[str, Any] = {'id': item_id}

    if session_state_key == 'select_items':
        new_item['column'] = None
        new_item['agg_func'] = 'none'
        st.session_state.select_items.append(new_item)
    elif session_state_key == 'where_conditions':
        new_item['logical'] = 'AND'
        new_item['column'] = None
        new_item['operator'] = '='
        new_item['value'] = ''
        st.session_state.where_conditions.append(new_item)
    elif session_state_key == 'joins':
        new_item['type'] = 'INNER JOIN'
        new_item['right_table'] = None
        new_item['on_conditions'] = []
        st.session_state.joins.append(new_item)
    elif session_state_key == 'on_conditions':
        for join in st.session_state.joins:
            if join['id'] == parent_id:
                join['on_conditions'].append({
                    'id': item_id, 
                    'left_col': None, 
                    'right_col': None
                })
                break

def remove_item(session_state_key: str, item_id: str, parent_id: Optional[str] = None) -> None:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‰Šé™¤ã™ã‚‹"""
    if parent_id:
        for join in st.session_state.joins:
            if join['id'] == parent_id:
                join['on_conditions'] = [
                    c for c in join['on_conditions'] 
                    if c.get('id') != item_id
                ]
                break
    else:
        st.session_state[session_state_key] = [
            item for item in st.session_state[session_state_key] 
            if item.get('id') != item_id
        ]

# --- UIæç”»é–¢æ•° ---
def render_condition_builder(builder_title, session_state_key, all_columns):
    st.write(f"**{builder_title}**")
    
    op_display_list = list(OPERATORS.values())
    op_internal_list = list(OPERATORS.keys())
    
    for i, condition in enumerate(st.session_state[session_state_key]):
        cols = st.columns([1.5, 3, 2, 3, 1])
        if i > 0:
            condition['logical'] = cols[0].radio("", ("AND", "OR"), key=f"logic_{condition['id']}", horizontal=True, label_visibility="collapsed", help="å‰ã®æ¡ä»¶ã¨ã“ã®æ¡ä»¶ã‚’ã€Œã‹ã¤(AND)ã€ã§ç¹‹ãã‹ã€ã€Œã¾ãŸã¯(OR)ã€ã§ç¹‹ãã‹é¸æŠã—ã¾ã™ã€‚")
        else:
            cols[0].empty()
        condition['column'] = cols[1].selectbox("ã‚«ãƒ©ãƒ ", all_columns, key=f"col_{condition['id']}",
            index=all_columns.index(condition['column']) if condition.get('column') in all_columns else None,
            placeholder="æ¡ä»¶ã‚’è¨­å®šã™ã‚‹åˆ—...", label_visibility="collapsed")
        
        current_op_index = op_internal_list.index(condition['operator']) if condition.get('operator') in op_internal_list else 0
        
        selected_op_display = cols[2].selectbox("æ¼”ç®—å­", op_display_list,
            key=f"op_disp_{condition['id']}", index=current_op_index, label_visibility="collapsed")
        condition['operator'] = op_internal_list[op_display_list.index(selected_op_display)]

        if condition['operator'] not in ['IS NULL', 'IS NOT NULL']:
            condition['value'] = cols[3].text_input("å€¤", key=f"val_{condition['id']}", value=condition.get('value', ''), label_visibility="collapsed", help="æ¯”è¼ƒã—ãŸã„å€¤ã‚’å…¥åŠ›ã—ã¾ã™ã€‚è¤‡æ•°é¸æŠã®å ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§æŒ‡å®šã—ã¾ã™ (ä¾‹: A,B,C)")
        else:
            cols[3].empty()
        cols[4].button("ğŸ—‘ï¸", key=f"del_{condition['id']}", on_click=remove_item, args=(session_state_key, condition['id']), help="ã“ã®æ¡ä»¶ã‚’å‰Šé™¤")
    st.button(f"â• æ¡ä»¶ã‚’è¿½åŠ ", key=f"add_{session_state_key}", on_click=add_item, args=(session_state_key,))

# --- 1. ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é¸æŠ ---
with st.expander("STEP 1: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹/ã‚¹ã‚­ãƒ¼ãƒ/ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠ", expanded=True):
    try:
        db_df = session.sql("SHOW DATABASES").collect()
        db_names = [row['name'] for row in db_df]
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"); db_names = []
    selected_db = st.selectbox('ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„:', db_names, index=None, placeholder="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’é¸æŠ...")

    selected_schema = None
    table_names = []
    if selected_db:
        try:
            schema_df = session.sql(f'SHOW SCHEMAS IN DATABASE "{selected_db}"').collect()
            schema_names = [row['name'] for row in schema_df if row['name'] not in ('INFORMATION_SCHEMA', 'PUBLIC')]
            selected_schema = st.selectbox('ã‚¹ã‚­ãƒ¼ãƒã‚’é¸æŠã—ã¦ãã ã•ã„:', schema_names, index=None, placeholder="ã‚¹ã‚­ãƒ¼ãƒã‚’é¸æŠ...")
            if selected_schema:
                 table_df = session.sql(f'SHOW TABLES IN SCHEMA "{selected_db}"."{selected_schema}"').collect()
                 table_names = [row['name'] for row in table_df]
        except Exception as e:
            st.warning(f"ã‚¹ã‚­ãƒ¼ãƒã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    st.write("**ä¸»ãƒ†ãƒ¼ãƒ–ãƒ«**", help="åˆ†æã®èµ·ç‚¹ã¨ãªã‚‹ã€æœ€ã‚‚ä¸»è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    selected_table = st.selectbox('ã‚¯ã‚¨ãƒªã®èµ·ç‚¹ã¨ãªã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:', table_names, index=None, placeholder="ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠ...", label_visibility="collapsed")

    if selected_table:
        st.markdown("---")
        st.write("**ãƒ†ãƒ¼ãƒ–ãƒ«çµåˆ (JOIN)**", help="ä¸»ãƒ†ãƒ¼ãƒ–ãƒ«ã«åˆ¥ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç¹‹ã’ã¦ã€è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã¾ãŸã„ã åˆ†æã‚’è¡Œã„ãŸã„å ´åˆã«è¿½åŠ ã—ã¾ã™ã€‚")
        
        for i, join in enumerate(st.session_state.joins):
            st.markdown(f"**JOIN {i+1}**")
            cols = st.columns([2,3,1])
            
            tables_in_joins_so_far = [selected_table] + [j['right_table'] for j in st.session_state.joins if j['right_table']]
            available_tables_for_join = [t for t in table_names if t not in tables_in_joins_so_far or t == join.get('right_table')]
            
            join_display_list = list(JOIN_TYPES.values())
            join_internal_list = list(JOIN_TYPES.keys())
            current_join_index = join_internal_list.index(join['type']) if join.get('type') in join_internal_list else 0

            selected_join_display = cols[0].selectbox("çµåˆã‚¿ã‚¤ãƒ—", join_display_list, key=f"join_type_disp_{join['id']}", index=current_join_index, label_visibility="collapsed")
            join['type'] = join_internal_list[join_display_list.index(selected_join_display)]
            
            join['right_table'] = cols[1].selectbox("çµåˆã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«", available_tables_for_join, key=f"join_table_{join['id']}", label_visibility="collapsed", placeholder="çµåˆãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠ...")
            cols[2].button("ğŸ—‘ï¸ ã“ã®çµåˆã‚’å‰Šé™¤", key=f"remove_join_{join['id']}", on_click=remove_item, args=('joins', join['id']))

            if join['right_table']:
                 st.write("ONå¥ (çµåˆæ¡ä»¶)")
                 st.caption("ã©ã®åˆ—ã‚’åŸºæº–ã«ãƒ†ãƒ¼ãƒ–ãƒ«åŒå£«ã‚’ç¹‹ãã‹ã‚’æŒ‡å®šã—ã¾ã™ã€‚é€šå¸¸ã¯ä¸¡ãƒ†ãƒ¼ãƒ–ãƒ«ã«å…±é€šã™ã‚‹IDã‚„ã‚³ãƒ¼ãƒ‰ã®åˆ—ã‚’é¸æŠã—ã¾ã™ã€‚")

                 tables_before_this_join = [selected_table]
                 for j_index in range(i):
                     prev_join = st.session_state.joins[j_index]
                     if prev_join.get('right_table'):
                         tables_before_this_join.append(prev_join['right_table'])
                
                 left_cols_options = []
                 for tbl in tables_before_this_join:
                     left_cols_options.extend(get_qualified_table_columns(selected_db, selected_schema, tbl))
                 
                 right_cols_options = get_qualified_table_columns(selected_db, selected_schema, join['right_table'])

                 for on_cond in join['on_conditions']:
                     on_cols = st.columns([4,1,4,1])
                     on_cond['left_col'] = on_cols[0].selectbox("å·¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚«ãƒ©ãƒ ", left_cols_options, key=f"on_left_{on_cond['id']}", label_visibility="collapsed")
                     on_cols[1].markdown("<p style='text-align: center; margin-top: 10px;'>=</p>", unsafe_allow_html=True)
                     on_cond['right_col'] = on_cols[2].selectbox("å³ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚«ãƒ©ãƒ ", right_cols_options, key=f"on_right_{on_cond['id']}", label_visibility="collapsed")
                     on_cols[3].button("ğŸ—‘ï¸", key=f"remove_on_{on_cond['id']}", on_click=remove_item, args=('on_conditions', on_cond['id'], join['id']))
                 st.button("â• ONæ¡ä»¶ã‚’è¿½åŠ ", key=f"add_on_{join['id']}", on_click=add_item, args=('on_conditions', join['id']))
            st.markdown("---")

        if len(st.session_state.joins) < 2:
            st.button("â• ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’çµåˆ", on_click=add_item, args=('joins',))

# --- 2. SQLã®é …ç›®ã¨æ¡ä»¶ã®æŒ‡å®š ---
qualified_columns = []
is_aggregation_used = False
if selected_table:
    all_tables_in_query = [selected_table]
    if 'joins' in st.session_state:
        all_tables_in_query.extend([j['right_table'] for j in st.session_state.joins if j.get('right_table')])
    
    for tbl in list(set(all_tables_in_query)):
        qualified_columns.extend(get_qualified_table_columns(selected_db, selected_schema, tbl))

    with st.expander("STEP 2: SQLã®é …ç›®ã¨æ¡ä»¶ã‚’æŒ‡å®š", expanded=True):
        # ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã®è¡¨ç¤º
        st.write("**ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©**")
        valid_tables = [tbl for tbl in all_tables_in_query if tbl]
        if valid_tables:
            tab_list = st.tabs([f"ğŸ“œ {tbl}" for tbl in valid_tables])
            for i, table_name in enumerate(valid_tables):
                with tab_list[i]:
                    definition_df = get_table_definition(selected_db, selected_schema, table_name)
                    if not definition_df.empty:
                        st.dataframe(definition_df, use_container_width=True)
                    else:
                        st.warning(f"{table_name} ã®å®šç¾©ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.info("STEP1ã§ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã™ã‚‹ã¨ã€ã“ã“ã«å®šç¾©ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
        
        st.markdown("---")

        if not qualified_columns:
            st.warning("ã‚¯ã‚¨ãƒªå¯¾è±¡ã®ã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚STEP1ã§ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠãƒ»è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            st.write("**1. è¡¨ç¤ºãƒ»é›†è¨ˆã™ã‚‹é …ç›®ã‚’é¸æŠ**")
            st.caption("é›†è¨ˆæ–¹æ³•ã§`(ãªã—)`ã‚’é¸æŠã—ãŸé …ç›®ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’ã¾ã¨ã‚ã‚‹ï¼ˆGROUP BYï¼‰ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚")
            
            agg_display_list = list(AGG_FUNCS.values())
            agg_internal_list = list(AGG_FUNCS.keys())

            for item in st.session_state.select_items:
                cols = st.columns([4, 3, 1])
                item['column'] = cols[0].selectbox("ã‚«ãƒ©ãƒ ", qualified_columns, key=f"scol_{item['id']}",
                    index=qualified_columns.index(item['column']) if item.get('column') in qualified_columns else None,
                    label_visibility="collapsed", placeholder="è¡¨ç¤ºã—ãŸã„åˆ—...")
                
                current_agg_index = agg_internal_list.index(item['agg_func']) if item.get('agg_func') in agg_internal_list else 0
                
                selected_agg_display = cols[1].selectbox("é›†è¨ˆæ–¹æ³•", agg_display_list,
                    key=f"agg_disp_{item['id']}", index=current_agg_index, label_visibility="collapsed")
                item['agg_func'] = agg_internal_list[agg_display_list.index(selected_agg_display)]

                cols[2].button("ğŸ—‘ï¸", key=f"sdel_{item['id']}", on_click=remove_item, args=('select_items', item['id']), help="ã“ã®é …ç›®ã‚’å‰Šé™¤")
            st.button("â• é …ç›®ã‚’è¿½åŠ ", on_click=add_item, args=('select_items',))
            is_aggregation_used = any(item.get('agg_func') != 'none' for item in st.session_state.select_items)

            st.markdown("---")
            render_condition_builder("2. WHEREå¥ã®æ¡ä»¶ã‚’æŒ‡å®š (é›†è¨ˆå‰ã®çµã‚Šè¾¼ã¿)", 'where_conditions', qualified_columns)

# --- 3. SQLã®ç”Ÿæˆã¨å®Ÿè¡Œ ---
def build_condition_clause(session_state_key: str, all_columns: List[str]) -> str:
    """æ¡ä»¶å¥ã‚’æ§‹ç¯‰ã™ã‚‹"""
    parts = []
    for i, cond in enumerate(st.session_state[session_state_key]):
        cond_str = ""
        if (cond.get('column') in all_columns and 
            (cond.get('operator') not in ['IS NULL', 'IS NOT NULL'] or cond.get('value') is not None)):
            
            op, val, col_name = cond['operator'], cond['value'], cond['column']
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
            if not validate_sql_value(str(val)):
                logger.warning(f"å±é™ºãªå€¤ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {val}")
                continue
                
            if op in ['IS NULL', 'IS NOT NULL']:
                cond_str = f"{col_name} {op}"
            elif op == 'IN':
                items = [f"'{item.strip()}'" for item in str(val).split(',') if item.strip()]
                if items: 
                    cond_str = f"{col_name} IN ({', '.join(items)})"
            elif 'LIKE' in op:
                like_val = str(val).replace("'", "''")
                if op == 'LIKE_PARTIAL':
                    cond_str = f"{col_name} LIKE '%{like_val}%'"
                elif op == 'LIKE_FORWARD':
                    cond_str = f"{col_name} LIKE '{like_val}%'"
                elif op == 'LIKE_BACKWARD':
                    cond_str = f"{col_name} LIKE '%{like_val}'"
            else:
                # æ•°å€¤ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
                if str(val).replace('.', '').replace('-', '').isdigit():
                    formatted_val = val
                else:
                    # ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                    escaped_val = str(val).replace("'", "''")
                    formatted_val = f"'{escaped_val}'"
                cond_str = f"{col_name} {op} {formatted_val}"
                
        if cond_str:
            parts.append(f"{cond['logical']} {cond_str}" if i > 0 else cond_str)
    return "\n  ".join(parts) if parts else ""

def generate_sql_query(selected_db: str, selected_schema: str, selected_table: str, 
                      qualified_columns: List[str], is_aggregation_used: bool) -> str:
    """SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹"""
    try:
        # SELECTå¥ã®æ§‹ç¯‰
        select_parts = []
        groupby_parts = []
        for item in st.session_state.select_items:
            if item.get('column') in qualified_columns:
                col_name = item["column"]
                agg_func = item.get('agg_func', 'none')
                if agg_func == 'none':
                    select_parts.append(col_name)
                    if is_aggregation_used:
                        groupby_parts.append(col_name)
                elif agg_func == 'COUNT(DISTINCT)':
                    select_parts.append(f"COUNT(DISTINCT {col_name})")
                else:
                    select_parts.append(f"{agg_func}({col_name})")
        
        select_clause = ",\n    ".join(select_parts) if select_parts else "*"
        
        # FROMå¥ã®æ§‹ç¯‰
        full_from_clause = f'FROM "{selected_db}"."{selected_schema}"."{selected_table}"'
        for join in st.session_state.joins:
            if join.get('right_table') and join.get('on_conditions'):
                on_clause_parts = []
                join_type_str = join["type"]
                for on_cond in join['on_conditions']:
                    if on_cond.get('left_col') and on_cond.get('right_col'):
                        on_clause_parts.append(f"{on_cond['left_col']} = {on_cond['right_col']}")
                if on_clause_parts:
                    full_from_clause += f'\n  {join_type_str} "{selected_db}"."{selected_schema}"."{join["right_table"]}"\n    ON {" AND ".join(on_clause_parts)}'
        
        # SQLã‚¯ã‚¨ãƒªã®çµ„ã¿ç«‹ã¦
        generated_sql = f"SELECT\n    {select_clause}\n{full_from_clause}"

        # WHEREå¥ã®è¿½åŠ 
        where_clause = build_condition_clause('where_conditions', qualified_columns)
        if where_clause: 
            generated_sql += f"\nWHERE\n  {where_clause}"
        
        # GROUP BYå¥ã®è¿½åŠ 
        if is_aggregation_used and groupby_parts:
            generated_sql += f"\nGROUP BY\n    {', '.join(groupby_parts)}"
        
        generated_sql += ";"
        
        logger.info("SQLã‚¯ã‚¨ãƒªã‚’æ­£å¸¸ã«ç”Ÿæˆã—ã¾ã—ãŸ")
        return generated_sql
        
    except Exception as e:
        error_msg = f"SQLã‚¯ã‚¨ãƒªã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        logger.error(error_msg)
        st.error(error_msg)
        return ""

def execute_sample_query(sql_query: str) -> Optional[pd.DataFrame]:
    """ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹"""
    if not sql_query:
        return None
        
    try:
        execution_sql = sql_query.rstrip(';') + " LIMIT 10;"
        result_df = session.sql(execution_sql).to_pandas()
        logger.info("ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã‚’æ­£å¸¸ã«å®Ÿè¡Œã—ã¾ã—ãŸ")
        return result_df
    except Exception as e:
        handle_database_error("ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ", e)
        return None

if selected_table:
    with st.expander("STEP 3: SQLã‚’ç¢ºèªã—ã¦å®Ÿè¡Œ", expanded=True):
        # SQLã‚¯ã‚¨ãƒªã®ç”Ÿæˆ
        if selected_schema:  # selected_schemaãŒNoneã§ãªã„ã“ã¨ã‚’ç¢ºèª
            generated_sql = generate_sql_query(
                selected_db, selected_schema, selected_table, 
                qualified_columns, is_aggregation_used
            )
            
            if generated_sql:
                st.write("#### ç”Ÿæˆã•ã‚ŒãŸSQL")
                st.code(generated_sql, language='sql')
                
                if st.button('ğŸš€ ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ (10è¡Œ)', type="primary"):
                    st.write("#### å®Ÿè¡Œçµæœ (æœ€åˆã®10è¡Œ)")
                    with st.spinner('ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œä¸­ã§ã™...'):
                        result_df = execute_sample_query(generated_sql)
                        if result_df is not None:
                            st.dataframe(result_df, use_container_width=True)
                            st.success(f"æœ€å¤§10è¡Œã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
            else:
                st.error("SQLã‚¯ã‚¨ãƒªã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            st.error("ã‚¹ã‚­ãƒ¼ãƒãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚STEP1ã§ã‚¹ã‚­ãƒ¼ãƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
